{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Text Tokenization and Embeddings for Language Modeling\n",
        "\n",
        "[Token vizualize](https://tiktokenizer.vercel.app/)"
      ],
      "metadata": {
        "id": "6d2EwtsVO58s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/the-verdict.txt\",'r',encoding='utf-8') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "Hz2MnsJDO8D9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YxLUEUvCQLXs",
        "outputId": "4bb57dbd-46dd-406d-8402-65163aa8962c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvDf8B59QQ29",
        "outputId": "e02098a5-02ce-4c21-8618-198a37344b21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20479"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"I HAD always thought Jack Gisburn rather a cheap genius--though a\"\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', data)"
      ],
      "metadata": {
        "id": "muPqf2ahQdxf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "preprocessed = result"
      ],
      "metadata": {
        "id": "PH2yxcXhRWT2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbPOY2ddRXqz",
        "outputId": "3ebe5794-b645-466e-e146-04b73e71f4bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# converting it the token to token id"
      ],
      "metadata": {
        "id": "O9ROffZZSQoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = list(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBsoggcvRhOJ",
        "outputId": "64e4079a-03d5-4636-aca2-e7c27936e323"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {vocab:interger for interger,vocab in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "PeQOp_GQSYHE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'\"lift': 0,\n",
        " 'across': 1,\n",
        " 'accuse': 2,\n",
        " 'knew?': 3,\n",
        " 'covered': 4,......}"
      ],
      "metadata": {
        "id": "OAPeDCCYSu-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "SuySbWUvSnzv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding (encode):** Splits input text into tokens using the same regex as before.\n",
        "Filters out empty tokens.\n",
        "Converts each token to its corresponding ID using `str_to_int`.\n",
        "Returns a list of token IDs."
      ],
      "metadata": {
        "id": "zB6owczzVNs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoding (decode):**\n",
        "Converts a list of token IDs back to tokens using int_to_str.\n",
        "Joins tokens with spaces to form a string.\n",
        "Uses regex `(re.sub)` to remove extra spaces before punctuation `(e.g., \"word ,\" → \"word,\")`."
      ],
      "metadata": {
        "id": "0FwK7JS3VUuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)"
      ],
      "metadata": {
        "id": "Qj7bB-dqUagG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I HAD always thought Jack Gisburn rather a cheap genius--though a\"\n",
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJRJBT4CUlSl",
        "outputId": "f0760e5e-c7e4-4e73-9b40-5a4aeaa47d3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[920, 571, 747, 180, 780, 58, 666, 712, 505, 285, 401, 499, 712]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([675, 573, 805, 942, 433, 607, 759, 804, 939, 475, 210, 241, 804])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DJeCmH4nT_a6",
        "outputId": "106756e1-d9de-49cb-b12c-e5f734745791"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go jealousy occurred absurdity is? Victor recreated charming now effects You recreated'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4ZkmzK-jwh",
        "outputId": "a1bf59e0-dd89-4720-dadc-df9f635e64ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'HAD',\n",
              " 'always',\n",
              " 'thought',\n",
              " 'Jack',\n",
              " 'Gisburn',\n",
              " 'rather',\n",
              " 'a',\n",
              " 'cheap',\n",
              " 'genius']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_words.extend([\"<|endoftext|>\",\"<junk|>\"])"
      ],
      "metadata": {
        "id": "X-yfFpehVgZS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:interger for interger,token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "dnY1VS3l-zUZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yltlOTE-4_R",
        "outputId": "5fbf92b2-ae4a-48ba-c571-ab006be40aad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(i,item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGvXL_mP-7fP",
        "outputId": "56a610fd-17e8-4385-9a99-ddbf4a852cd6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ('Gideon', 1127)\n",
            "1 ('am', 1128)\n",
            "2 ('secret', 1129)\n",
            "3 ('<|endoftext|>', 1130)\n",
            "4 ('<junk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int else \"<junk|>\" for item in preprocessed\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "o9ivzs6D_ExC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)"
      ],
      "metadata": {
        "id": "9Hn8WPpkI4V1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = text + \" Rohit\"\n",
        "tokenizer.encode(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61lRm9fJcMw",
        "outputId": "7bcba997-41a2-4b15-84a5-417d582a77f9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[920, 571, 747, 180, 780, 58, 666, 712, 505, 285, 401, 499, 712, 1131]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nZTzwr0ZJdnZ",
        "outputId": "34da6776-3b18-4222-de41-bd357c27e81e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius -- though a <junk|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Byte Pair encoding"
      ],
      "metadata": {
        "id": "wfocLRJ7Q8wV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using tiktoken library to utilize the byte pair algo used in the gpt2"
      ],
      "metadata": {
        "id": "GXx68ccIVDQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tiktoken\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "vZKgeR9lJkaX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `tiktoken` library provides a `pre-trained` BPE tokenizer for GPT-2.\n",
        "BPE is a more sophisticated tokenization method that splits text into subword units, balancing vocabulary size and coverage."
      ],
      "metadata": {
        "id": "TKmpATGEV3Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "xdZrIBSuVL8j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### here two word yet three encode (because it is using byte pair encoding)"
      ],
      "metadata": {
        "id": "tF8VYC5KWB9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Hello rohit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F1itPBWVdj6",
        "outputId": "ac2ae3de-58b6-4f39-ff69-c450a97bd189"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15496, 686, 17945]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([15496, 686, 17945])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zpSogWalVhv6",
        "outputId": "81dd200d-27dc-4a99-9775-d5ca2751cf11"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello rohit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"hello <|endoftext|>\",allowed_special={'<|endoftext|>'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3FZuwB2W0T7",
        "outputId": "cde428f1-d6dd-4816-9261-9300d256cfd9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31373, 220, 50256]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data sampling with a sliding window"
      ],
      "metadata": {
        "id": "jJ67DXR-Z2uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/the-verdict.txt\",'r',encoding='utf-8') as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "5PfDY8LsYlwf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)\n",
        "len(enc_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wAburAuayB_",
        "outputId": "6082ae71-8e88-4dce-d50c-dd5e9d18ad54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5145"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "context_size = 4\n",
        "enc_sample = enc_text[:50]\n",
        "for i in range(1,context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(context,\" --> \",desired)\n",
        "  print(gpt_tokenizer.decode(context),\" --> \",gpt_tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKRk92Iha3mA",
        "outputId": "25a31e2f-646b-429a-a27d-2c11794167f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40]  -->  367\n",
            "I  -->   H\n",
            "[40, 367]  -->  2885\n",
            "I H  -->  AD\n",
            "[40, 367, 2885]  -->  1464\n",
            "I HAD  -->   always\n",
            "[40, 367, 2885, 1464]  -->  1807\n",
            "I HAD always  -->   thought\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "frgQ9-M7cyDC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p1QUI63ggWUi",
        "outputId": "f199cdc5-6cad-4bf5-85f3-bb2ba22a80b9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What Are Inputs and Targets?**"
      ],
      "metadata": {
        "id": "24qcMaipu2KB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Inputs:` These are the sequences of tokens (or token IDs) that the model takes as input during training. They represent the context or the portion of the text the model sees to make predictions.\n"
      ],
      "metadata": {
        "id": "Yo2MuwyevEtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Targets:` These are the sequences of tokens that the model is expected to predict based on the inputs. They represent the \"correct answers\" or the next tokens in the sequence."
      ],
      "metadata": {
        "id": "_2lUd13FvIFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose the tokenized text is `[40, 367, 2885, 1464, 1807]` (decoded as “`I HAD always thought`”), and max_length=4, stride=1. The dataset creates pairs like this:"
      ],
      "metadata": {
        "id": "tVvuey5LvX7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First pair:\n",
        "`Input: [40, 367, 2885, 1464] (“I HAD always”)`\n",
        "\n",
        "```\n",
        "Target: [367, 2885, 1464, 1807] (“HAD always thought”)\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "Second pair (slide window by 1):\n",
        "Input: [367, 2885, 1464, 1807] (“HAD always thought”)\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "Target: [2885, 1464, 1807, ...] (“always thought ...”)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Jz8V4lVvvadL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Shift the Target by One Token?**"
      ],
      "metadata": {
        "id": "OqDGe2dcxiVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target sequence is shifted by one token because the goal of the language model is to predict the next token given the current context. For example:"
      ],
      "metadata": {
        "id": "hV3W22QUxsXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the input is `[40, 367, 2885]` `(“I HAD always”)`, the model should predict the next token 1464 (“thought”).\n",
        "By providing the target sequence `[367, 2885, 1464, 1807]`, the model can compare its predictions to the actual next tokens and learn from the errors.\n",
        "This is called next-token prediction, a core concept in autoregressive language models like GPT."
      ],
      "metadata": {
        "id": "czOR853mxviA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "J6jmQn5kgxW0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "0Xy372gDjnm5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "ZFRwiJqvj6xS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input chunk: A sequence of max_length tokens (e.g., `[40, 367, 2885, 1464]`).\n",
        "Target chunk: The same sequence shifted one token forward (e.g., `[367, 2885, 1464, 1807])`."
      ],
      "metadata": {
        "id": "neiydkKM9gPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQNdIx4GkHyc",
        "outputId": "119c0d69-1e0c-49e0-f69e-32cd20a942cf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTVXac5HkT6E",
        "outputId": "dbce3c0f-2b43-4c9f-c70e-4bd6c6f9157b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token embedding"
      ],
      "metadata": {
        "id": "ustPa4NCpLxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tokenizer)[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asbrJdjPTOI2",
        "outputId": "36be89b8-5b76-4dfc-e0fa-e9b9cda12863"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['max_token_value',\n",
              " 'n_vocab',\n",
              " 'name',\n",
              " 'special_tokens_set',\n",
              " 'token_byte_values']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.n_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2jFp6E1nUKC",
        "outputId": "8553a2eb-65cb-45d6-d6e4-3d70e99662c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What Is Token Embedding?**\n",
        "A token embedding is a dense, continuous vector representation of a token in a vocabulary. Each token (e.g., a word, subword, or special character) is mapped to a fixed-size vector of real numbers, where the vector captures semantic information about the token. These vectors are typically learned during training and allow the model to understand relationships between tokens based on their meanings or context."
      ],
      "metadata": {
        "id": "hSyFojlsDXxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  The token “cat” might be represented as a 256-dimensional vector like `[0.2, -0.5, 0.1, ..., 0.3]`\n",
        "*  The token “dog” might have a similar but slightly different vector, reflecting their semantic similarity (both are animals)."
      ],
      "metadata": {
        "id": "8duR7kQvDiIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([1,2,3])\n",
        "vocab_size = 6\n",
        "output_size = 3\n",
        "\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_size)\n",
        "embedding_layer.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSedRFkzTaea",
        "outputId": "c03fbf89-d12d-48ae-a0ce-448187d6b05b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.0981,  0.5051,  1.2166],\n",
              "        [-1.0484, -0.3839,  0.7467],\n",
              "        [-1.9080, -0.4061,  1.2185],\n",
              "        [-0.1899,  1.0797, -0.9287],\n",
              "        [ 1.9656,  0.3913,  0.2022],\n",
              "        [-0.2758, -0.8194,  0.8391]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = embedding_layer(input_ids)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCaXMWttT8oJ",
        "outputId": "19c8ca9d-d476-49bb-d578-20f4eefceafb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0484, -0.3839,  0.7467],\n",
              "        [-1.9080, -0.4061,  1.2185],\n",
              "        [-0.1899,  1.0797, -0.9287]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Word Encoding"
      ],
      "metadata": {
        "id": "U5VNSLJMVSt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional encoding is a method to represent the position of each token in a sequence as a numerical vector that can be combined with the token’s embedding. This allows the model to understand not just what the tokens are (via token embeddings) but also their order in the sequence (e.g., whether a word is the first, second, or third in a sentence)."
      ],
      "metadata": {
        "id": "hnxNGP3K5k6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, in the sentence “I love to code”:"
      ],
      "metadata": {
        "id": "k1IEs1CX5vZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   The token “love” has a different meaning or role depending on whether it’s the first word, second word, or last word.\n",
        "2.   Positional encoding adds information to tell the model that “love” is the second token in this sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "Uy6gO8oh5w-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without positional encoding, a transformer model would treat the sentence as a “bag of words,” ignoring the order, which could lead to incorrect interpretations (e.g., `“I love to code”` might be treated the same as `“Code to love I”`)."
      ],
      "metadata": {
        "id": "Nh65BmoV55sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer models process all tokens in a sequence simultaneously (in parallel) using self-attention mechanisms. `Unlike RNNs or LSTMs`, which process tokens sequentially, **transformers don’t inherently know the order of tokens**.\n",
        "Positional encoding provides this order information explicitly."
      ],
      "metadata": {
        "id": "p6S-VLSz6Io0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Order Matters in Language:**"
      ],
      "metadata": {
        "id": "sqONluGw6dkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The meaning of a sentence often depends on the order of words. For example, **“The dog chased the cat”** is different from **“The cat chased the dog.”** Positional encoding ensures the model can distinguish these cases."
      ],
      "metadata": {
        "id": "ibr5NXyP6gYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enabling Context-Aware Predictions:**"
      ],
      "metadata": {
        "id": "PqO3q_yR6pty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In language modeling, the model predicts the next token based on the context of previous tokens. Positional encoding helps the model understand the relative positions of tokens in the context, which is critical for accurate predictions."
      ],
      "metadata": {
        "id": "zifG4UcY6r0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "6z0KGBY_UVms"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A token embedding layer is created to convert token IDs (from the GPT-2 tokenizer’s vocabulary of `50,257` tokens) into `256-dimensional vectors`."
      ],
      "metadata": {
        "id": "_FXA8n1r73zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "max_length = 4\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"batch size : \",8)\n",
        "print(\"max lenght : \",4)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq8VXK-2Vzkp",
        "outputId": "607af61b-3aa8-49ca-d3fc-80d7992c7a2c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size :  8\n",
            "max lenght :  4\n",
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How Does Positional Encoding Work in Practice?**"
      ],
      "metadata": {
        "id": "liqN4lFu_04a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose the input batch (inputs) contains one sequence: `[40, 367, 2885, 1464]` (decoded as “I HAD always”)."
      ],
      "metadata": {
        "id": "WM0_3nK3_3a8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token Embeddings:\n",
        "Each token ID is converted to a 256-dimensional vector:\n",
        "*  40 (“I”) → [0.1, -0.2, ..., 0.5]\n",
        "(example vector)\n",
        "*  367 (“HAD”) → [-0.3, 0.4, ..., -0.1]\n",
        "*  2885 (“always”) → [0.2, 0.1, ..., 0.3]\n",
        "*  1464 → [0.0, -0.5, ..., 0.2]\n",
        "*  Shape: [1, 4, 256] (for one sequence)."
      ],
      "metadata": {
        "id": "IUEz7zJc_80U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Embeddings:**\n",
        "The positions `[0, 1, 2, 3]` are converted to 256-dimensional vectors:\n",
        "*  Position 0 → `[0.01, -0.02, ..., 0.03]`\n",
        "*  Position 1 → `[-0.01, 0.04, ..., -0.02]`\n",
        "*  Position 2 → `[0.02, 0.01, ..., 0.05]`\n",
        "*  Position 3 → `[0.00, -0.03, ..., 0.01]`\n",
        "*  Shape: `[4, 256]`"
      ],
      "metadata": {
        "id": "KilAlzsJAT6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token Embedding**"
      ],
      "metadata": {
        "id": "7GjlE7CBD8Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip30-OQGWS9X",
        "outputId": "20bac4c3-f98b-414f-cf13-d06e32799ef1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Position Embedding**"
      ],
      "metadata": {
        "id": "EKuk4mUyEDDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
      ],
      "metadata": {
        "id": "FaM1avorWd9k"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)\n",
        "print(pos_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcVq2QbJZsd2",
        "outputId": "ed19896c-33dc-4acf-d14b-3ef6b354d2bb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n",
            "tensor([[-1.9388, -0.0067,  0.8084,  ...,  0.5857, -1.1943, -0.2662],\n",
            "        [-1.2178,  0.6031, -1.0661,  ...,  0.1578,  1.0267,  0.1040],\n",
            "        [ 1.2363,  0.2505, -1.1435,  ...,  0.0201, -1.7183, -0.2860],\n",
            "        [-1.0928, -0.9578,  1.0012,  ..., -0.5694,  0.6425,  0.8918]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combining Embeddings:**\n",
        "For each token, the token embedding and positional embedding are added:\n",
        "*  For “I” (position 0): `token_embedding(40) + pos_embedding(0)`\n",
        "*  For “HAD” (position 1): `token_embedding(367) + pos_embedding(1)`\n",
        "*  And so on.\n",
        "The result is a new tensor where each token’s vector encodes both its meaning and its position."
      ],
      "metadata": {
        "id": "pGQCGm29AtD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o126L4SC7ha",
        "outputId": "d1067e07-fc40-4c3f-91d7-ba061bd496d1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WEMOSMSC-0Q",
        "outputId": "3da01b7c-e18c-4186-8bba-0abb722936d4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What Does Broadcasting Look Like?**"
      ],
      "metadata": {
        "id": "JtoszCWeFDiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_=\"\"\"\n",
        "pos_embeddings = [\n",
        "  [p0],  # Position 0: [0.01, -0.02, ..., 0.03] (256D vector)\n",
        "  [p1],  # Position 1: [-0.01, 0.04, ..., -0.02]\n",
        "  [p2],  # Position 2: [0.02, 0.01, ..., 0.05]\n",
        "  [p3]   # Position 3: [0.00, -0.03, ..., 0.01]\n",
        "]  # Shape: [4, 256]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AGdYWRZrF2--"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_=\"\"\"\n",
        "pos_embeddings_broadcasted = [\n",
        "  [  # Batch 1\n",
        "    [p0],  # Position 0\n",
        "    [p1],  # Position 1\n",
        "    [p2],  # Position 2\n",
        "    [p3]   # Position 3\n",
        "  ],\n",
        "  [  # Batch 2\n",
        "    [p0],  # Same position 0\n",
        "    [p1],  # Same position 1\n",
        "    [p2],\n",
        "    [p3]\n",
        "  ],\n",
        "  ...,  # Repeated for all 8 batches\n",
        "]  # Shape: [8, 4, 256]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7KfwdSjiGAJR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIQL2UawZ1ek",
        "outputId": "9bdb67d2-fba0-4d3e-bb27-e189f84ce2d0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cl-niUSZ6Sg"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}